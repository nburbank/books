{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import bottlenose\n",
    "import xmltodict\n",
    "from urllib2 import HTTPError\n",
    "import time\n",
    "import math\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your username: ''\n",
      "Enter your userid: ''\n",
      "Enter your key: ''\n",
      "Enter your associate tag: ''\n",
      "you entered \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the secret data into your code\n",
    "username = input('Enter your username: ')\n",
    "user_id = input('Enter your userid: ')\n",
    "key = input('Enter your key: ')\n",
    "associate = input('Enter your associate tag: ')\n",
    "\n",
    "print 'you entered '\n",
    "print username\n",
    "print user_id\n",
    "print key\n",
    "print associate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# monitor the success of this process\n",
    "num_entries_from_db = 0\n",
    "num_unique_titles = 0\n",
    "num_isbn_successes = 0\n",
    "num_title_successes = 0\n",
    "num_description_successes = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6ddf5431595e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# set up bottlenose to query amazon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mamazon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbottlenose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAmazon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthentication_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthentication_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthentication_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'associate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "# import credentials and create the isntance for the amazon account\n",
    "\n",
    "# read my data from a file in json format \n",
    "file_name_and_path = '/Users/noahburbank/keys/aws_credentials.csv'\n",
    "h = open(file_name_and_path, 'r')\n",
    "authentication_list = json.loads(h.read())\n",
    "\n",
    "# make it into a dictionary for ease of use\n",
    "authentication_dict = dict()\n",
    "authentication_dict['username'] = str(authentication_list[0])\n",
    "authentication_dict['user_id'] = str(authentication_list[1])\n",
    "authentication_dict['key'] = str(authentication_list[2])\n",
    "authentication_dict['associate'] = str(authentication_list[3])\n",
    "\n",
    "# set up bottlenose to query amazon\n",
    "amazon = bottlenose.Amazon(authentication_dict['id'], authentication_dict['key'], authentication_dict['associate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fetch data from the database that's going to be enhanced\n",
    "\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "def pull_from_database(start,stop):\n",
    "    #pull data from the database\n",
    "    con = psycopg2.connect(\"dbname='nytimes'\") \n",
    "    cur = con.cursor()    \n",
    "    cur.execute(\"SELECT distinct * from books where (list ='Combined Hardcover & Paperback Fiction');\")\n",
    "    rows = cur.fetchall()\n",
    "    con.close()\n",
    "\n",
    "    # import as a dataframe\n",
    "    data_frame = pd.DataFrame()\n",
    "    data_frame = pd.DataFrame(data = rows, columns=('id','title', 'isbn', 'author', 'list', 'rank', 'date', 'weeks on list', 'description', 'contributor', 'publisher', 'updated frequency' ) )\n",
    "\n",
    "    #partition data into a smaller set for trouble shooting and the such\n",
    "    title_list = data_frame['title'][start:stop]\n",
    "    isbn_list = data_frame['isbn'][start:stop]\n",
    "    isbn_title_dict = dict(zip(isbn_list,title_list))\n",
    "    #these are the things returned \n",
    "\n",
    "    print \"pulled \" + str(stop - start -1) + \" entries from the database\"\n",
    "    print \"there were \" + str(len(set(title_list))) + \" unique titles\"\n",
    "\n",
    "    return [title_list, isbn_list, isbn_title_dict,len(set(title_list)), (stop-start-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# search by isbn function\n",
    "def search_by_isbn(isbn):\n",
    "    if isbn == 'None':\n",
    "        return 'no isbn'\n",
    "    response = amazon.ItemLookup(IdType = \"ISBN\", ItemId=isbn, SearchIndex = \"Books\", ResponseGroup='Large')\n",
    "    obj1 = xmltodict.parse(response)\n",
    "    if 'Item' in obj1['ItemLookupResponse']['Items'].keys():\n",
    "        if type(obj1['ItemLookupResponse']['Items']['Item']) == list:\n",
    "            return obj1['ItemLookupResponse']['Items']['Item'][0]['ASIN']\n",
    "        else:\n",
    "            return obj1['ItemLookupResponse']['Items']['Item']['ASIN']\n",
    "    else: #this happens with the isbn doens't get a response, becuase it's probably wrong\n",
    "        return 'isbn to asin failure'\n",
    "\n",
    "    \n",
    "    \n",
    "def pull_amazon_by_isbn(isbn_list):    \n",
    "    \n",
    "    # first pass, try to get as many ASIN for ISBN out of the list\n",
    "    isbn_to_asin = dict()\n",
    "\n",
    "    counter = 0 \n",
    "    # run through the isbn list from the database\n",
    "    for isbn in set(isbn_list):\n",
    "        isbn_to_asin[isbn] = search_by_isbn(isbn)\n",
    "#        print isbn_to_asin[isbn]\n",
    "        # pause to avoid 503 errors\n",
    "        time.sleep(1)\n",
    "        \n",
    "        #display progress\n",
    "#        print (len(set(isbn_list)) - counter) \n",
    "        counter += 1\n",
    "        \n",
    "    # calculate the success rate\n",
    "    success_count = 0\n",
    "    for value in isbn_to_asin.values():\n",
    "        if value != 'isbn to asin failure':\n",
    "            if value != 'no isbn':\n",
    "                success_count += 1\n",
    "    print \n",
    "    print \"the isbn success rate is \" + str((success_count+0.0)/len(isbn_to_asin))\n",
    "\n",
    "    return [isbn_to_asin,success_count]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def list_failures():\n",
    "    # make a list of the titles of the failed books, try to get ASIN using a title match\n",
    "    covered_books = dict()\n",
    "    uncovered_books = list()\n",
    "    for key in isbn_to_asin:\n",
    "        if isbn_to_asin[key] == 'isbn to asin failure':\n",
    "            uncovered_books.append(isbn_title_dict[key])\n",
    "        elif isbn_to_asin[key] == 'no isbn':\n",
    "            uncovered_books.append(isbn_title_dict[key])\n",
    "        else:\n",
    "            covered_books[isbn_title_dict[key]]= isbn_to_asin[key]\n",
    "    len(uncovered_books)\n",
    "    return [covered_books, uncovered_books]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# search by title to produce potential matches\n",
    "def search_by_title(title):\n",
    "    # construct the query\n",
    "    response=amazon.ItemSearch(Keywords=title, SearchIndex=\"Books\")\n",
    "    # parse xml\n",
    "    obj2 = xmltodict.parse(response)\n",
    "    # construct a dictionary of title:ASIN from that author\n",
    "    title_asin_dict = dict()\n",
    "    for object in obj2['ItemSearchResponse']['Items']['Item']:\n",
    "        title_asin_dict[object['ItemAttributes']['Title']] = object['ASIN']    \n",
    "    return title_asin_dict\n",
    "\n",
    "\n",
    "def infer_asin_from_titles():\n",
    "    uncovered_title_asin_dict = dict()\n",
    "    inferred_asin_dict = dict()\n",
    "\n",
    "    for ex_title in uncovered_books:\n",
    "        time.sleep(2)\n",
    "\n",
    "        # step 1: get the potential matches\n",
    "        potential_titles = search_by_title(ex_title)\n",
    "\n",
    "        # step 2: identify matches with title as subset\n",
    "        filtered_matches = dict()\n",
    "        for title in potential_titles:\n",
    "            if re.search(ex_title.lower(),title.lower()) != None:\n",
    "                filtered_matches[title] = potential_titles[title]\n",
    "\n",
    "        if len(filtered_matches) == 0:\n",
    "            uncovered_title_asin_dict[ex_title] = 'no match'\n",
    "    #        print \"no matches for \" + str(ex_title)\n",
    "    #        print\n",
    "            continue\n",
    "#        else:\n",
    "#            print ex_title\n",
    "\n",
    "        # step 3: identify most frequent ASIN\n",
    "        time.sleep(2)\n",
    "\n",
    "        asin_rank_dict = dict()\n",
    "        for filtered_match in filtered_matches:\n",
    "            match_asin = filtered_matches[filtered_match]\n",
    "            response=amazon.ItemLookup(ItemId=match_asin, ResponseGroup='Large')\n",
    "            # parse xml\n",
    "            obj2 = xmltodict.parse(response)\n",
    "\n",
    "            if 'SalesRank' in obj2['ItemLookupResponse']['Items']['Item']:\n",
    "                sales_rank = int(obj2['ItemLookupResponse']['Items']['Item']['SalesRank'])\n",
    "                book_asin = obj2['ItemLookupResponse']['Items']['Item']['ASIN']        \n",
    "                asin_rank_dict[sales_rank] = book_asin\n",
    "            else:\n",
    "                print \"no sales rank found\"   \n",
    "\n",
    "        uncovered_title_asin_dict[ex_title] = asin_rank_dict\n",
    "\n",
    "        # step 4: find the best ranked book\n",
    "\n",
    "        best_rank = min(set(asin_rank_dict.keys()))\n",
    "#        print best_rank\n",
    "#        print len(asin_rank_dict)\n",
    "\n",
    "        inferred_asin = asin_rank_dict[best_rank]\n",
    "#        print inferred_asin\n",
    "        inferred_asin_dict[ex_title] = inferred_asin\n",
    "    total_title_successes = len(set(inferred_asin_dict.keys()))\n",
    "    return [uncovered_title_asin_dict, inferred_asin_dict, total_title_successes]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# function to take a response and extract author, title, description, nodelist, and isbn\n",
    "def parse_xml(query_response): \n",
    "    # parse response\n",
    "    obj3 = xmltodict.parse(query_response)\n",
    "    # get the title\n",
    "    \n",
    "    if 'Author' in obj3['ItemLookupResponse']['Items']['Item']['ItemAttributes'].keys():\n",
    "#        print \"ok zone\"\n",
    "        author = obj3['ItemLookupResponse']['Items']['Item']['ItemAttributes']['Author']\n",
    "        title = obj3['ItemLookupResponse']['Items']['Item']['ItemAttributes']['Title']    \n",
    "\n",
    "        if 'EditorialReviews' in obj3['ItemLookupResponse']['Items']['Item'].keys():            \n",
    "            description =  obj3['ItemLookupResponse']['Items']['Item']['EditorialReviews']\n",
    "            if type(description['EditorialReview']) == list:\n",
    "                description = description['EditorialReview'][0]['Content']\n",
    "            else:\n",
    "                description = description['EditorialReview']['Content']\n",
    "        else:\n",
    "            description = 'None'\n",
    "\n",
    "        # pull out the list of \n",
    "        node_list = list()\n",
    "        for node in obj3['ItemLookupResponse']['Items']['Item']['BrowseNodes']['BrowseNode']:\n",
    "\n",
    "            if type(node) == list:\n",
    "                node_list.append( \"'\" + str(node[0]['Name']) + \"'\")    \n",
    "            elif type(node) == unicode:\n",
    "                do_nothing = node \n",
    "#                print node\n",
    "            else:\n",
    "                node_list.append( \"'\" + str(node['Name']) + \"'\") \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        # pull the isbn number as well\n",
    "        if 'ISBN' in obj3['ItemLookupResponse']['Items']['Item']['ItemAttributes'].keys():\n",
    "            isbn = obj3['ItemLookupResponse']['Items']['Item']['ItemAttributes']['ISBN']\n",
    "        else:\n",
    "            isbn = 'None'\n",
    "        \n",
    "        return [title, author, description, node_list, isbn]\n",
    "#    else:\n",
    "#        print 'not ok zone'\n",
    "        \n",
    "def extract_and_input():\n",
    "    # go over the covered books and extract their data for the data fram\n",
    "\n",
    "    df = pd.DataFrame(columns = ['title', 'author', 'description', 'nodelist', 'isbn'])\n",
    "    values_list = list()\n",
    "    \n",
    "    counter = 0\n",
    "    for book in z: \n",
    "        time.sleep(1)\n",
    "        title = book\n",
    "        asin = z[book]\n",
    "        search = amazon.ItemLookup(ItemId=asin, ResponseGroup='Large')\n",
    "#        print title\n",
    "#        print (len(z) - counter)\n",
    "        values = parse_xml(search)\n",
    "        df.loc[counter] = values\n",
    "        values_list.append(values)\n",
    "\n",
    "        counter += 1\n",
    "    return [values_list, df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def put_in_database(results_as_a_list):    \n",
    "    con = None\n",
    "    con = psycopg2.connect(database='nytimes') \n",
    "    cur = con.cursor()\n",
    "    query = \"INSERT INTO amazon (title, author, description, nodelist, isbn) VALUES (%s, %s, %s, %s, %s)\"\n",
    "    cur.executemany(query, results_as_a_list)\n",
    "    con.commit()\n",
    "    con.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "so far 0,100\n",
    "100,200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulled 589 entries from the database\n",
      "there were 188 unique titles\n",
      "\n",
      "the isbn success rate is 1.0\n",
      "total entries\n",
      "589\n",
      "unique titles\n",
      "188\n",
      "isbn successes\n",
      "200\n",
      "title successes\n",
      "0\n",
      "description successes\n",
      "187\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## run the whole code from one place \n",
    "##\n",
    "\n",
    "num_description_successes = 0\n",
    "\n",
    "[title_list, isbn_list, isbn_title_dict, num_unique_titles, num_entries_from_db] = pull_from_database(1,591)\n",
    "[isbn_to_asin,num_isbn_successes] = pull_amazon_by_isbn(isbn_list)\n",
    "[covered_books, uncovered_books] = list_failures()\n",
    "[uncovered_title_asin_dict, inferred_asin_dict, num_title_successes] = infer_asin_from_titles()\n",
    "\n",
    "\n",
    "# combine collected and inferred asin's\n",
    "z = covered_books.copy()\n",
    "z.update(inferred_asin_dict)\n",
    "\n",
    "[values_list, df] =  extract_and_input()\n",
    "\n",
    "\n",
    "pure_values_list = list()\n",
    "# remove the failures, uggh so many steps losing at each step\n",
    "for value in values_list:\n",
    "    if value != None:\n",
    "        pure_values_list.append(value)\n",
    "        num_description_successes += 1\n",
    "        \n",
    "#actually put the data into the database\n",
    "put_in_database(pure_values_list)\n",
    "\n",
    "##\n",
    "## report on achievements \n",
    "##\n",
    "\n",
    "print 'total entries'\n",
    "print num_entries_from_db\n",
    "print 'unique titles'\n",
    "print num_unique_titles\n",
    "print 'isbn successes'\n",
    "print num_isbn_successes\n",
    "print 'title successes'\n",
    "print num_title_successes\n",
    "print 'description successes'\n",
    "print num_description_successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
